{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the gensim model into spacy model didn't work (couldn't convert the gensim model) \n",
    "\n",
    "# import spacy\n",
    "# # Load the spacy model that you have installed\n",
    "# nlp = spacy.load('./word2vec_model_one_gesim.model/')\n",
    "# # process a sentence using the model\n",
    "# doc = nlp(\"This is some text that I am processing with Spacy\")\n",
    "# # It's that simple - all of the vectors and words are assigned after this point\n",
    "# # Get the vector for 'text':\n",
    "# doc[3].vector\n",
    "# # Get the mean vector for the entire sentence (useful for sentence classification etc.)\n",
    "# doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import string\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name:str, path:str =\"\"):\n",
    "    return gensim.models.Word2Vec.load(path + name)\n",
    "# model = gensim.models.Word2Vec.load(\"word2vec_model_one_gesim.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name: str, path:str=\"\"):\n",
    "    return pd.read_csv(path + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_question_data(data, is_training):\n",
    "    question1_data = data[\"question1\"].values.tolist()\n",
    "    question2_data = data[\"question2\"].values.tolist()\n",
    "    if is_training:\n",
    "        labels = data[\"is_duplicate\"].values.tolist()\n",
    "        return [question1_data, question2_data, labels]\n",
    "    return [question1_data, question2_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data (tokenizing and removing punctutation)\n",
    "def gensim_preprocess(question_data):\n",
    "    return [gensim.utils.simple_preprocess(str(sentence)) for sentence in question_data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_preprocess(question_data):\n",
    "    stop_words=['the', 'a', 'an', 'and', 'is', 'be', 'will']\n",
    "    new_data = []\n",
    "    \n",
    "    for question in question_data:\n",
    "        processed_question = []\n",
    "        question = str(question)\n",
    "        \n",
    "        #split the question to words (doesn't include stop words)\n",
    "        words = [word.lower() for word in question.split() if word not in stop_words]\n",
    "        for word in words:\n",
    "            # to remove punctutation from string (imported from string library)\n",
    "            word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "            word = word.replace('“', '').replace('”', '')\n",
    "\n",
    "            if len(word) > 0:\n",
    "                processed_question.append(word)\n",
    "                \n",
    "        new_data.append(processed_question)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_embedding (model ,data:str):\n",
    "    data_embedding = []\n",
    "    for sentence in data:\n",
    "        data_embedding.append(get_sentence_embedding(model, sentence))\n",
    "\n",
    "    return data_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding (model ,sentence:str):\n",
    "    sentence_embedding = []\n",
    "    for word in sentence:\n",
    "        sentence_embedding.append(get_word_embedding(model, word))\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding (model ,word:str):\n",
    "    try: \n",
    "        return model.wv[word]\n",
    "    #     model.wv.get_vector[word]\n",
    "    except: \n",
    "        return model.wv[\"UNK\"]\n",
    "    return model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_of_embeddings(data_embedding, embedding_size):\n",
    "    return [sum(sentence)/len(sentence) if len(sentence)>0 else np.zeros(embedding_size) \n",
    "            for sentence in data_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_size(data):\n",
    "    for sentence in data:\n",
    "        if len(sentence) >0:\n",
    "            return len(sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(question1_summed_vector, question2_summed_vector): \n",
    "    distance = []\n",
    "    for i in range(len(question1_summed_vector)):\n",
    "        distance.append(1 - spatial.distance.cosine(question1_summed_vector[i], question2_summed_vector[i]))\n",
    "        \n",
    "    for i in range(len(distance)):\n",
    "        if math.isnan(distance[i]):\n",
    "            distance[i] = 0\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_gensim = load_model(\"word2vec_model_gensim_100.model\")\n",
    "# model_manual = load_model(\"word2vec_model_manual_100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gensim = load_model(\"word2vec_model_gensim_200.model\")\n",
    "model_manual = load_model(\"word2vec_model_manual_200.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "[question1_data, question2_data, labels] = read_question_data(df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_clean_question1_data = gensim_preprocess(question1_data)\n",
    "gensim_clean_question2_data = gensim_preprocess(question2_data)\n",
    "\n",
    "manual_clean_question1_data = string_preprocess(question1_data)\n",
    "manual_clean_question2_data = string_preprocess(question2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_question1_data_vector = get_data_embedding(model_gensim, gensim_clean_question1_data)\n",
    "gensim_question2_data_vector = get_data_embedding(model_gensim, gensim_clean_question2_data)\n",
    "\n",
    "manual_question1_data_vector = get_data_embedding(model_manual, manual_clean_question1_data)\n",
    "manual_question2_data_vector = get_data_embedding(model_manual, manual_clean_question2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "embedding_size_gensim = get_embedding_size(gensim_question1_data_vector)\n",
    "embedding_size_manual = get_embedding_size(manual_question1_data_vector)\n",
    "\n",
    "print(embedding_size_gensim)\n",
    "\n",
    "gensim_question1_summed_vector = get_sum_of_embeddings(gensim_question1_data_vector, embedding_size_gensim)\n",
    "gensim_question2_summed_vector = get_sum_of_embeddings(gensim_question2_data_vector, embedding_size_gensim)\n",
    "\n",
    "manual_question1_summed_vector = get_sum_of_embeddings(manual_question1_data_vector, embedding_size_manual)\n",
    "manual_question2_summed_vector = get_sum_of_embeddings(manual_question2_data_vector, embedding_size_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadye\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "distances_gensim = cosine_similarity(gensim_question1_summed_vector, gensim_question2_summed_vector)\n",
    "distances_manual = cosine_similarity(manual_question1_summed_vector, manual_question2_summed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_gensim = LogisticRegression(random_state=0).fit(np.array(distances_gensim).reshape(-1,1), np.array(labels))\n",
    "clf_manual = LogisticRegression(random_state=0).fit(np.array(distances_manual).reshape(-1,1), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm model took too long to train compared to logistic regression, so opted not to train it now\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# svm_gensim = make_pipeline(StandardScaler(), SVC(gamma='auto')).fit(np.array(distances_gensim).reshape(-1,1), np.array(labels))\n",
    "\n",
    "# svm_manual = make_pipeline(StandardScaler(), SVC(gamma='auto')).fit(np.array(distances_manual).reshape(-1,1), np.array(labels))\n",
    "\n",
    "# filename = 'svm_gensim_model.sav'\n",
    "# pickle.dump(svm_gensim, open(filename, 'wb'))\n",
    "\n",
    "# filename = 'svm_manual_model.sav'\n",
    "# pickle.dump(svm_manual, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = read_csv('test.csv')\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "[question1_test_data, question2_test_data] = read_question_data(df_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_clean_question1_test_data = gensim_preprocess(question1_test_data)\n",
    "gensim_clean_question2_test_data = gensim_preprocess(question2_test_data)\n",
    "\n",
    "manual_clean_question1_test_data = string_preprocess(question1_test_data)\n",
    "manual_clean_question2_test_data = string_preprocess(question2_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_question1_test_data_vector = get_data_embedding(model_gensim, gensim_clean_question1_test_data)\n",
    "gensim_question2_test_data_vector = get_data_embedding(model_gensim, gensim_clean_question2_test_data)\n",
    "\n",
    "manual_question1_test_data_vector = get_data_embedding(model_manual, manual_clean_question1_test_data)\n",
    "manual_question2_test_data_vector = get_data_embedding(model_manual, manual_clean_question2_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size_gensim = get_embedding_size(gensim_question1_test_data_vector)\n",
    "embedding_size_manual = get_embedding_size(manual_question1_test_data_vector)\n",
    "    \n",
    "\n",
    "gensim_question1_summed_test_vector = get_sum_of_embeddings(gensim_question1_test_data_vector, embedding_size_gensim)\n",
    "gensim_question2_summed_test_vector = get_sum_of_embeddings(gensim_question2_test_data_vector, embedding_size_gensim)\n",
    "\n",
    "manual_question1_summed_test_vector = get_sum_of_embeddings(manual_question1_test_data_vector, embedding_size_manual)\n",
    "manual_question2_summed_test_vector = get_sum_of_embeddings(manual_question2_test_data_vector, embedding_size_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadye\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "test_distances_gensim = cosine_similarity(gensim_question1_summed_test_vector, gensim_question2_summed_test_vector)\n",
    "test_distances_manual = cosine_similarity(manual_question1_summed_test_vector, manual_question2_summed_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345796\n",
      "2345796\n"
     ]
    }
   ],
   "source": [
    "print(len(test_distances_gensim))\n",
    "print(len(test_distances_manual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model_pred_logistic = clf_gensim.predict(np.array(test_distances_gensim).reshape(-1,1))\n",
    "manual_model_pred_logistic = clf_manual.predict(np.array(test_distances_manual).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = list(range(0,len(gensim_model_pred_logistic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'test_id':sample_id,'is_duplicate':list(gensim_model_pred_logistic)})\n",
    "submission.to_csv('gensim_logistic_pred_200.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = pd.DataFrame({'test_id':sample_id,'is_duplicate':list(manual_model_pred_logistic)})\n",
    "submission2.to_csv('manual_logistic_pred_200.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
