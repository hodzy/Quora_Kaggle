{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "import math\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
    "\n",
    "\n",
    "# freezing the model's parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the step by step guide to invest in share market in india?', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?', 'How can I increase the speed of my internet connection while using a VPN?', 'Why am I mentally very lonely? How can I solve it?', 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?']\n",
      "['What is the step by step guide to invest in share market?', 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', 'How can Internet speed be increased by hacking through DNS?', 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?', 'Which fish would survive in salt water?']\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"./Data/question_similarity/train.csv\", encoding=\"ISO-8859-1\")\n",
    "training_data.head()\n",
    "question_1 = training_data['question1'].tolist()\n",
    "question_2 = training_data['question2'].tolist()\n",
    "\n",
    "for i in range(len(question_1)):\n",
    "    question_1[i] = str(question_1[i])\n",
    "    question_2[i] = str(question_2[i])\n",
    "    \n",
    "labels = data['is_duplicate'].tolist()\n",
    "\n",
    "# binary_labels = torch.tensor(binary_labels)\n",
    "print(question_1[0:5])\n",
    "print(question_2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_id                                          question1  \\\n",
      "0        0  How does the Surface Pro himself 4 compare wit...   \n",
      "1        1  Should I have a hair transplant at age 24? How...   \n",
      "2        2  What but is the best way to send money from Ch...   \n",
      "3        3                        Which food not emulsifiers?   \n",
      "4        4                   How \"aberystwyth\" start reading?   \n",
      "\n",
      "                                           question2  \n",
      "0  Why did Microsoft choose core m3 and not core ...  \n",
      "1        How much cost does hair transplant require?  \n",
      "2                      What you send money to China?  \n",
      "3                                  What foods fibre?  \n",
      "4                     How their can I start reading?  \n",
      "['What is the step by step guide to invest in share market in india?', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?', 'How can I increase the speed of my internet connection while using a VPN?', 'Why am I mentally very lonely? How can I solve it?', 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?']\n",
      "['What is the step by step guide to invest in share market?', 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', 'How can Internet speed be increased by hacking through DNS?', 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?', 'Which fish would survive in salt water?']\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"./Data/question_similarity/test.csv\", encoding=\"ISO-8859-1\")\n",
    "print(test_data.head())\n",
    "test_question_1 = training_data['question1'].tolist()\n",
    "test_question_2 = training_data['question2'].tolist()\n",
    "\n",
    "for i in range(len(question_1)):\n",
    "    test_question_1[i] = str(test_question_1[i])\n",
    "    test_question_2[i] = str(test_question_2[i])\n",
    "    \n",
    "# binary_labels = torch.tensor(binary_labels)\n",
    "print(test_question_1[0:5])\n",
    "print(test_question_2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f1e1b43108>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAWeUlEQVR4nO3dbYyd5X3n8e9vcSEPXWIIG4u10ZooVlsCzYZYQJtVNQpdMBDFvAiSWbSYFMnaiDRpF6kxmxfsJkEialVatAkrq7hAFIVQmi5WICUW4ShaKRCgiQiEUGaBhSk0JGugcbJ5cPa/L841ytnhXJ4nM3OMvx/paO77f1/Xfa5rzsz8fD+c41QVkiSN889WewCSpMllSEiSugwJSVKXISFJ6jIkJElda1Z7AIfaCSecUBs3blxUnx/96Ee88Y1vfHUGtEKcw2RwDpPBOSzeQw899IOq+hdz66+5kNi4cSMPPvjgovoMBgOmpqZenQGtEOcwGZzDZHAOi5fkf42re7pJktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLU9Zp7x/Vq2bjzzoNuf/raC1ZoJJJ06HgkIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkrrmDYkku5O8kOSRkdofJ/lukoeT/E2StSPbrkoyneTxJOeO1Le02nSSnSP1k5Pcn+SJJF9IcnSrH9PWp9v2jYdq0pKkhVnIkcRNwJY5tb3AqVX1m8DfA1cBJDkF2Aa8vfX5TJKjkhwFfBo4DzgFuLi1BfgUcF1VbQJeBC5v9cuBF6vqbcB1rZ0kaQXNGxJV9TVg35zaV6rqQFu9D9jQlrcCt1bVT6vqKWAaOKM9pqvqyar6GXArsDVJgPcAt7f+NwMXjuzr5rZ8O3B2ay9JWiGH4r8v/T3gC215PcPQmDXTagDPzqmfCbwZeGkkcEbbr5/tU1UHkrzc2v9g7gCS7AB2AKxbt47BYLCoCezfv3/Rfea68rQDB92+3P3P51DMYbU5h8ngHCbDpMxhWSGR5GPAAeBzs6UxzYrxRyx1kPYH29cri1W7gF0Amzdvrqmpqf6gxxgMBiy2z1yXzfd/XF+yvP3P51DMYbU5h8ngHCbDpMxhySGRZDvwXuDsqpr94z0DnDTSbAPwXFseV/8BsDbJmnY0Mdp+dl8zSdYAb2LOaS9J0qtrSbfAJtkCfBR4X1X9eGTTHmBbuzPpZGAT8A3gAWBTu5PpaIYXt/e0cLkXeH/rvx24Y2Rf29vy+4GvjoSRJGkFzHskkeTzwBRwQpIZ4GqGdzMdA+xt15Lvq6r/UFWPJrkN+A7D01BXVNUv2n4+BNwNHAXsrqpH21N8FLg1ySeBbwI3tvqNwGeTTDM8gth2COYrSVqEeUOiqi4eU75xTG22/TXANWPqdwF3jak/yfDup7n1nwAXzTc+SdKrx3dcS5K6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdc0bEkl2J3khySMjteOT7E3yRPt6XKsnyfVJppM8nOT0kT7bW/snkmwfqb8rybdbn+uT5GDPIUlaOQs5krgJ2DKnthO4p6o2Afe0dYDzgE3tsQO4AYZ/8IGrgTOBM4CrR/7o39DazvbbMs9zSJJWyLwhUVVfA/bNKW8Fbm7LNwMXjtRvqaH7gLVJTgTOBfZW1b6qehHYC2xp246tqq9XVQG3zNnXuOeQJK2QpV6TWFdVzwO0r29p9fXAsyPtZlrtYPWZMfWDPYckaYWsOcT7y5haLaG+uCdNdjA8ZcW6desYDAaL6r9///5F95nrytMOHHT7cvc/n0Mxh9XmHCaDc5gMkzKHpYbE95KcWFXPt1NGL7T6DHDSSLsNwHOtPjWnPmj1DWPaH+w5XqGqdgG7ADZv3lxTU1O9pmMNBgMW22euy3beedDtT1+yvP3P51DMYbU5h8ngHCbDpMxhqaeb9gCzdyhtB+4YqV/a7nI6C3i5nSq6GzgnyXHtgvU5wN1t2w+TnNXuarp0zr7GPYckaYXMeySR5PMMjwJOSDLD8C6la4HbklwOPANc1JrfBZwPTAM/Bj4AUFX7knwCeKC1+3hVzV4M/yDDO6heD3y5PTjIc0iSVsi8IVFVF3c2nT2mbQFXdPazG9g9pv4gcOqY+v8e9xySpJXjO64lSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSug71x3K8pm2c513VkvRa45GEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldywqJJH+Y5NEkjyT5fJLXJTk5yf1JnkjyhSRHt7bHtPXptn3jyH6uavXHk5w7Ut/SatNJdi5nrJKkxVtySCRZD3wY2FxVpwJHAduATwHXVdUm4EXg8tblcuDFqnobcF1rR5JTWr+3A1uAzyQ5KslRwKeB84BTgItbW0nSClnu6aY1wOuTrAHeADwPvAe4vW2/GbiwLW9t67TtZydJq99aVT+tqqeAaeCM9piuqier6mfAra2tJGmFLPn/uK6qf0jyJ8AzwP8BvgI8BLxUVQdasxlgfVteDzzb+h5I8jLw5la/b2TXo32enVM/c9xYkuwAdgCsW7eOwWCwqLns379/QX2uPO3AvG16FjumxVroHCaZc5gMzmEyTMoclhwSSY5j+C/7k4GXgL9ieGporprt0tnWq487yqkxNapqF7ALYPPmzTU1NXWwob/CYDBgIX0u23nnovY76ulL5t//cix0DpPMOUwG5zAZJmUOyznd9LvAU1X1/ar6OfBF4LeBte30E8AG4Lm2PAOcBNC2vwnYN1qf06dXlyStkOWExDPAWUne0K4tnA18B7gXeH9rsx24oy3vaeu07V+tqmr1be3up5OBTcA3gAeATe1uqaMZXtzes4zxSpIWaTnXJO5Pcjvwd8AB4JsMT/ncCdya5JOtdmPrciPw2STTDI8gtrX9PJrkNoYBcwC4oqp+AZDkQ8DdDO+c2l1Vjy51vJKkxVtySABU1dXA1XPKTzK8M2lu258AF3X2cw1wzZj6XcBdyxmjJGnpfMe1JKnLkJAkdRkSkqQuQ0KS1LWsC9dauI3zvBHv6WsvWKGRSNLCeSQhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6lpWSCRZm+T2JN9N8liS30pyfJK9SZ5oX49rbZPk+iTTSR5OcvrIfra39k8k2T5Sf1eSb7c+1yfJcsYrSVqc5R5J/Dnwt1X168A7gMeAncA9VbUJuKetA5wHbGqPHcANAEmOB64GzgTOAK6eDZbWZsdIvy3LHK8kaRGWHBJJjgV+B7gRoKp+VlUvAVuBm1uzm4EL2/JW4JYaug9Ym+RE4Fxgb1Xtq6oXgb3Alrbt2Kr6elUVcMvIviRJK2DNMvq+Ffg+8JdJ3gE8BHwEWFdVzwNU1fNJ3tLarweeHek/02oHq8+Mqb9Ckh0MjzhYt24dg8FgURPZv3//gvpcedqBRe13MRY75rkWOodJ5hwmg3OYDJMyh+WExBrgdOD3q+r+JH/OL08tjTPuekItof7KYtUuYBfA5s2ba2pq6iDDeKXBYMBC+ly2885F7Xcxnr5k/uc/mIXOYZI5h8ngHCbDpMxhOdckZoCZqrq/rd/OMDS+104V0b6+MNL+pJH+G4Dn5qlvGFOXJK2QJYdEVf0j8GySX2uls4HvAHuA2TuUtgN3tOU9wKXtLqezgJfbaam7gXOSHNcuWJ8D3N22/TDJWe2upktH9iVJWgHLOd0E8PvA55IcDTwJfIBh8NyW5HLgGeCi1vYu4HxgGvhxa0tV7UvyCeCB1u7jVbWvLX8QuAl4PfDl9pAkrZBlhURVfQvYPGbT2WPaFnBFZz+7gd1j6g8Cpy5njJKkpfMd15KkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV3LDokkRyX5ZpIvtfWTk9yf5IkkX0hydKsf09an2/aNI/u4qtUfT3LuSH1Lq00n2bncsUqSFudQHEl8BHhsZP1TwHVVtQl4Ebi81S8HXqyqtwHXtXYkOQXYBrwd2AJ8pgXPUcCngfOAU4CLW1tJ0gpZs5zOSTYAFwDXAP8xSYD3AP+uNbkZ+M/ADcDWtgxwO/BfW/utwK1V9VPgqSTTwBmt3XRVPdme69bW9jvLGfOk2rjzzu62p6+9YAVHIkm/tKyQAP4M+CPgn7f1NwMvVdWBtj4DrG/L64FnAarqQJKXW/v1wH0j+xzt8+yc+pnjBpFkB7ADYN26dQwGg0VNYv/+/Qvqc+VpB+Zt82pYyNgWOodJ5hwmg3OYDJMyhyWHRJL3Ai9U1UNJpmbLY5rWPNt69XGnwmpMjaraBewC2Lx5c01NTY1r1jUYDFhIn8sO8q/9V9PTl0zN22ahc5hkzmEyOIfJMClzWM6RxLuB9yU5H3gdcCzDI4u1Sda0o4kNwHOt/QxwEjCTZA3wJmDfSH3WaJ9eXZK0ApZ84bqqrqqqDVW1keGF569W1SXAvcD7W7PtwB1teU9bp23/alVVq29rdz+dDGwCvgE8AGxqd0sd3Z5jz1LHK0lavOVekxjno8CtST4JfBO4sdVvBD7bLkzvY/hHn6p6NMltDC9IHwCuqKpfACT5EHA3cBSwu6oefRXGK0nqOCQhUVUDYNCWn+SXdyeNtvkJcFGn/zUM75CaW78LuOtQjFGStHi+41qS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlrySGR5KQk9yZ5LMmjST7S6scn2Zvkifb1uFZPkuuTTCd5OMnpI/va3to/kWT7SP1dSb7d+lyfJMuZrCRpcZZzJHEAuLKqfgM4C7giySnATuCeqtoE3NPWAc4DNrXHDuAGGIYKcDVwJnAGcPVssLQ2O0b6bVnGeCVJi7RmqR2r6nng+bb8wySPAeuBrcBUa3YzMAA+2uq3VFUB9yVZm+TE1nZvVe0DSLIX2JJkABxbVV9v9VuAC4EvL3XMh6uNO+886Panr71ghUYi6UhzSK5JJNkIvBO4H1jXAmQ2SN7Smq0Hnh3pNtNqB6vPjKlLklbIko8kZiX5VeCvgT+oqn86yGWDcRtqCfVxY9jB8LQU69atYzAYzDPq/9/+/fsX1OfK0w4sar8rZTAYLHgOk8w5TAbnMBkmZQ7LCokkv8IwID5XVV9s5e8lObGqnm+nk15o9RngpJHuG4DnWn1qTn3Q6hvGtH+FqtoF7ALYvHlzTU1NjWvWNRgMWEify+Y57bNanr5kasFzmGTOYTI4h8kwKXNYzt1NAW4EHquqPx3ZtAeYvUNpO3DHSP3SdpfTWcDL7XTU3cA5SY5rF6zPAe5u236Y5Kz2XJeO7EuStAKWcyTxbuDfA99O8q1W+0/AtcBtSS4HngEuatvuAs4HpoEfAx8AqKp9ST4BPNDafXz2IjbwQeAm4PUML1gfcRetJWk1Lefupv/B+OsGAGePaV/AFZ197QZ2j6k/CJy61DFKkpbHd1xLkroMCUlSlyEhSeoyJCRJXYaEJKlr2e+4fi2Z7zOSJtXGnXdy5WkHxr7Zz891krQcHklIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1OWb6V7j5nuDoG+2k3QwHklIkroMCUlSlyEhSerymsQRzmsWkg7GIwlJUpchIUnqMiQkSV1ek9BBHeyahdcrpNe+iT+SSLIlyeNJppPsXO3xSNKRZKKPJJIcBXwa+LfADPBAkj1V9Z3VHZnAO6OkI8FEhwRwBjBdVU8CJLkV2AoYEoeBxf6f4aP/T7cBI02GSQ+J9cCzI+szwJlzGyXZAexoq/uTPL7I5zkB+MGSRjghPvwam0M+tcqDWbrD/nXAOUyKlZ7DvxpXnPSQyJhavaJQtQvYteQnSR6sqs1L7T8JnMNkcA6TwTkcOpN+4XoGOGlkfQPw3CqNRZKOOJMeEg8Am5KcnORoYBuwZ5XHJElHjIk+3VRVB5J8CLgbOArYXVWPvgpPteRTVRPEOUwG5zAZnMMhkqpXnOKXJAmY/NNNkqRVZEhIkrqO6JA4HD/yI8lJSe5N8liSR5N8pNWPT7I3yRPt63GrPdb5JDkqyTeTfKmtn5zk/jaHL7SbFSZWkrVJbk/y3fZ6/Nbh9jok+cP2c/RIks8ned3h8Dok2Z3khSSPjNTGfu8zdH37PX84yemrN/Jf6szhj9vP08NJ/ibJ2pFtV7U5PJ7k3JUa5xEbEiMf+XEecApwcZJTVndUC3IAuLKqfgM4C7iijXsncE9VbQLuaeuT7iPAYyPrnwKua3N4Ebh8VUa1cH8O/G1V/TrwDoZzOWxehyTrgQ8Dm6vqVIY3h2zj8HgdbgK2zKn1vvfnAZvaYwdwwwqNcT438co57AVOrarfBP4euAqg/Y5vA97e+nym/Q171R2xIcHIR35U1c+A2Y/8mGhV9XxV/V1b/iHDP0zrGY795tbsZuDC1RnhwiTZAFwA/EVbD/Ae4PbWZKLnkORY4HeAGwGq6mdV9RKH2evA8A7H1ydZA7wBeJ7D4HWoqq8B++aUe9/7rcAtNXQfsDbJiSsz0r5xc6iqr1TVgbZ6H8P3hsFwDrdW1U+r6ilgmuHfsFfdkRwS4z7yY/0qjWVJkmwE3gncD6yrqudhGCTAW1ZvZAvyZ8AfAf+3rb8ZeGnkF2TSX4+3At8H/rKdMvuLJG/kMHodquofgD8BnmEYDi8DD3F4vQ6jet/7w/V3/feAL7flVZvDkRwSC/rIj0mV5FeBvwb+oKr+abXHsxhJ3gu8UFUPjZbHNJ3k12MNcDpwQ1W9E/gRE3xqaZx2zn4rcDLwL4E3Mjw1M9ckvw4Lcbj9bJHkYwxPLX9utjSm2YrM4UgOicP2Iz+S/ArDgPhcVX2xlb83ewjdvr6wWuNbgHcD70vyNMPTfO9heGSxtp32gMl/PWaAmaq6v63fzjA0DqfX4XeBp6rq+1X1c+CLwG9zeL0Oo3rf+8Pqdz3JduC9wCX1yzeyrdocjuSQOCw/8qOdu78ReKyq/nRk0x5ge1veDtyx0mNbqKq6qqo2VNVGht/3r1bVJcC9wPtbs0mfwz8Czyb5tVY6m+FH2B82rwPD00xnJXlD+7mancNh8zrM0fve7wEubXc5nQW8PHtaatIk2QJ8FHhfVf14ZNMeYFuSY5KczPAi/DdWZFBVdcQ+gPMZ3kHwP4GPrfZ4Fjjmf8PwMPNh4FvtcT7Dc/r3AE+0r8ev9lgXOJ8p4Ett+a3tB38a+CvgmNUe3zxj/9fAg+21+O/AcYfb6wD8F+C7wCPAZ4FjDofXAfg8w+soP2f4r+zLe997hqdqPt1+z7/N8G6uSZ3DNMNrD7O/2/9tpP3H2hweB85bqXH6sRySpK4j+XSTJGkehoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS1/8Dh9yrIBPhTrIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(question.split()) for question in question_1]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f181370308>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(question.split()) for question in question_2]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_training_data = tokenizer.__call__(question_1[0:5],question_2[0:5], \n",
    "                                   max_length=max_seq_len, \n",
    "                                   truncation=True,\n",
    "                                   padding=True,\n",
    "                                   return_token_type_ids=False,\n",
    "                                  return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "tokenized_test_data = tokenizer.__call__(test_question_1[0:5],test_question_2[0:5], \n",
    "                               max_length=max_seq_len, \n",
    "                               truncation=True, \n",
    "                               padding=True,\n",
    "                               return_token_type_ids=False,\n",
    "                               return_tensors=\"pt\")\n",
    "# tokenized_training_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2054,  2003,  1996,  3357,  2011,  3357,  5009,  2000, 15697,\n",
      "          1999,  3745,  3006,  1999,  2634,  1029,   102,  2054,  2003,  1996,\n",
      "          3357,  2011,  3357,  5009,  2000, 15697,  1999,  3745,  3006,  1029,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2003,  1996,  2466,  1997, 12849, 10606, 16506,  1006,\n",
      "         12849,  2232,  1011,  1045,  1011,  2053,  2953,  1007,  6323,  1029,\n",
      "           102,  2054,  2052,  4148,  2065,  1996,  2796,  2231, 10312,  1996,\n",
      "         12849, 10606, 16506,  1006, 12849,  2232,  1011,  1045,  1011,  2053,\n",
      "          2953,  1007,  6323,  2067,  1029,   102],\n",
      "        [  101,  2129,  2064,  1045,  3623,  1996,  3177,  1997,  2026,  4274,\n",
      "          4434,  2096,  2478,  1037, 21210,  2078,  1029,   102,  2129,  2064,\n",
      "          4274,  3177,  2022,  3445,  2011, 23707,  2083,  1040,  3619,  1029,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2572,  1045, 10597,  2200,  9479,  1029,  2129,  2064,\n",
      "          1045,  9611,  2009,  1029,   102,  2424,  1996,  6893,  2043,  1031,\n",
      "          8785,  1033,  2603,  1034,  1063,  2484,  1065,  1031,  1013,  8785,\n",
      "          1033,  2003,  4055,  2011,  2484,  1010,  2603,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2029,  2028, 21969,  1999,  2300, 21864,  2243,  2135,  5699,\n",
      "          1010,  5474,  1010, 24481,  1998,  6351,  4487, 15772,  1029,   102,\n",
      "          2029,  3869,  2052,  5788,  1999,  5474,  2300,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "{'input_ids': tensor([[  101,  2054,  2003,  1996,  3357,  2011,  3357,  5009,  2000, 15697,\n",
      "          1999,  3745,  3006,  1999,  2634,  1029,   102,  2054,  2003,  1996,\n",
      "          3357,  2011,  3357,  5009,  2000, 15697,  1999,  3745,  3006,  1029,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2054,  2003,  1996,  2466,  1997, 12849, 10606, 16506,  1006,\n",
      "         12849,  2232,  1011,  1045,  1011,  2053,  2953,  1007,  6323,  1029,\n",
      "           102,  2054,  2052,  4148,  2065,  1996,  2796,  2231, 10312,  1996,\n",
      "         12849, 10606, 16506,  1006, 12849,  2232,  1011,  1045,  1011,  2053,\n",
      "          2953,  1007,  6323,  2067,  1029,   102],\n",
      "        [  101,  2129,  2064,  1045,  3623,  1996,  3177,  1997,  2026,  4274,\n",
      "          4434,  2096,  2478,  1037, 21210,  2078,  1029,   102,  2129,  2064,\n",
      "          4274,  3177,  2022,  3445,  2011, 23707,  2083,  1040,  3619,  1029,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2339,  2572,  1045, 10597,  2200,  9479,  1029,  2129,  2064,\n",
      "          1045,  9611,  2009,  1029,   102,  2424,  1996,  6893,  2043,  1031,\n",
      "          8785,  1033,  2603,  1034,  1063,  2484,  1065,  1031,  1013,  8785,\n",
      "          1033,  2003,  4055,  2011,  2484,  1010,  2603,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2029,  2028, 21969,  1999,  2300, 21864,  2243,  2135,  5699,\n",
      "          1010,  5474,  1010, 24481,  1998,  6351,  4487, 15772,  1029,   102,\n",
      "          2029,  3869,  2052,  5788,  1999,  5474,  2300,  1029,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_training_data)\n",
    "print(tokenized_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "\n",
    "    def __init__(self, training_data, labels):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        self.training_data = training_data\n",
    "        self.labels = labels\n",
    "        self.n_samples = len(labels)\n",
    "\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        # returns (input_id, attention_mask, label)\n",
    "        return (self.training_data['input_ids'][index], self.training_data['attention_mask'][index], self.labels[index])\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity_Model(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(Spam_Model, self).__init__()\n",
    "        self.bert = bert\n",
    "#         self.relu_1 = nn.ReLU()\n",
    "\n",
    "        self.L1 = nn.Linear(768, 265)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.L2 = nn.Linear(265, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#         torch.nn.init.xavier_uniform(self.L1.weight)\n",
    "#         self.L1.bias.data.fill_(0.01)\n",
    "#         torch.nn.init.xavier_uniform(self.L2.weight)\n",
    "#         self.L2.bias.data.fill_(0.01)\n",
    "        \n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "            _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "            output = self.L1(cls_hs)\n",
    "#             print(output)\n",
    "            output = self.relu(output)\n",
    "            output = self.L2(output)\n",
    "            output = self.sigmoid(output)\n",
    "            return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = QuoraDataset(training_data, labels)\n",
    "test_data = QuoraDataset(tokenized_test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "training_data_loader = DataLoader(train_data, batch_size=64, sampler=train_sampler)\n",
    "val_data_loader = DataLoader(val_data, batch_size=64, shuffle=True)\n",
    "test_data_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataiter = iter(training_data_loader)\n",
    "# val_dataiter = iter(val_data_loader)\n",
    "# test_dataiter = iter(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = train_dataiter.next()\n",
    "# # len(output[0])\n",
    "# output[0][0]\n",
    "# # verbose, cls_hs= bert(train_dataiter.next())\n",
    "\n",
    "# for data in train_dataiter:\n",
    "#     print(data)\n",
    "    \n",
    "# len(data[0])\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "model = Similarity_Model(bert)\n",
    "# model = model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [50/975], Total Loss: 21.2042, Loss: 0.3006\n",
      "Epoch [1/5], Step [100/975], Total Loss: 20.1088, Loss: 0.6612\n",
      "Epoch [1/5], Step [150/975], Total Loss: 12.0120, Loss: 0.0487\n",
      "Epoch [1/5], Step [200/975], Total Loss: 16.5557, Loss: 0.7074\n",
      "Epoch [1/5], Step [250/975], Total Loss: 17.0691, Loss: 0.2521\n",
      "Epoch [1/5], Step [300/975], Total Loss: 14.2535, Loss: 0.4050\n",
      "Epoch [1/5], Step [350/975], Total Loss: 12.3993, Loss: 0.0187\n",
      "Epoch [1/5], Step [400/975], Total Loss: 13.3210, Loss: 0.0114\n",
      "Epoch [1/5], Step [450/975], Total Loss: 12.0070, Loss: 0.1329\n",
      "Epoch [1/5], Step [500/975], Total Loss: 12.2986, Loss: 1.0939\n",
      "Epoch [1/5], Step [550/975], Total Loss: 8.0921, Loss: 0.0010\n",
      "Epoch [1/5], Step [600/975], Total Loss: 14.8193, Loss: 0.3112\n",
      "Epoch [1/5], Step [650/975], Total Loss: 8.8135, Loss: 0.0268\n",
      "Epoch [1/5], Step [700/975], Total Loss: 9.5519, Loss: 0.0144\n",
      "Epoch [1/5], Step [750/975], Total Loss: 12.3649, Loss: 0.0024\n",
      "Epoch [1/5], Step [800/975], Total Loss: 8.2679, Loss: 0.4463\n",
      "Epoch [1/5], Step [850/975], Total Loss: 9.9445, Loss: 0.2114\n",
      "Epoch [1/5], Step [900/975], Total Loss: 13.9590, Loss: 0.2005\n",
      "Epoch [1/5], Step [950/975], Total Loss: 7.4825, Loss: 0.0364\n",
      "0\n",
      "Epoch [2/5], Step [50/975], Total Loss: 10.9431, Loss: 0.0163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-834-2b12ebcda2af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#         mask= mask.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#         labels = labels.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#         print(outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#         print(labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-827-57c011fa6710>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sent_id, mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#             print(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m         )\n\u001b[0;32m   1007\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m                 )\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         )\n\u001b[0;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         )\n\u001b[0;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1680\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1681\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1682\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dummy Training loop\n",
    "i=0\n",
    "num_epochs = 5\n",
    "total_samples = len(train_dataiter)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "total_loss = 0\n",
    "# print(total_samples, n_iterations)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (sent_id, mask, labels) in enumerate(training_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "#         sent_id = sent_id.to(device)\n",
    "#         mask= mask.to(device)\n",
    "#         labels = labels.to(device)\n",
    "        outputs = model(sent_id, mask)\n",
    "#         print(outputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs[:, 0], labels.float())\n",
    "        total_loss += loss\n",
    "#         print(loss)\n",
    "        # Backward and optimize\n",
    "\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(i)\n",
    "        if (i+1) % 50 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_samples}], Total Loss: {total_loss.item():.4f}, Loss: {loss.item():.4f}')\n",
    "            total_loss = 0\n",
    "        i+=1\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "correct_guesses = 0\n",
    "false_guesses = 0\n",
    "for i, (sent_id, mask, label) in enumerate(test_data_loader):\n",
    "    with torch.no_grad():\n",
    "        preds = model(sent_id, mask)\n",
    "        for i in range(len(preds)):\n",
    "            print(int(round(float(preds[i][0]))))\n",
    "            if int(round(float(preds[i][0]))) == label[i]:\n",
    "                correct_guesses += 1\n",
    "            else:\n",
    "                false_guesses += 1\n",
    "#             preds = preds.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n"
     ]
    }
   ],
   "source": [
    "print(correct_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "ex_inputs = tokenizer([\"Hello world!\", \"hello world 2\"], return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "# # The ** operator allows us to take a dictionary of key-value pairs and unpack it into keyword arguments in a ***function call***\n",
    "ex_outputs = bert(**ex_inputs)\n",
    "\n",
    "ex_outputs \n",
    "\n",
    "# print(ex_outputs.last_hidden_state.shape)\n",
    "# print(ex_outputs[0].shape)\n",
    "\n",
    "\n",
    "# print(ex_outputs.pooler_output.shape)\n",
    "print(ex_outputs[1].shape)\n",
    "\n",
    "# false usage (used in function calls)\n",
    "# print(**ex_inputs.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sentence_a = \"this is a sentence\"\n",
    "sentence_b = \"this is another sentence\"\n",
    "\n",
    "encoding = tokenizer(sentence_a, sentence_b, padding=True, truncation=True, \n",
    "                               max_length=30,  \n",
    "                               return_token_type_ids=False,\n",
    "                               return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 6251,  102, 2023, 2003, 2178, 6251,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
